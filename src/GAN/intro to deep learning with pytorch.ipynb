{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a68004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34bb8614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6559, -1.4390,  1.0892, -1.1670, -0.5405], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_layer(torch.tensor((1.0, 2.0, 3.0)))  # This will raise an error because the input is not a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer       = torch.nn.Linear( in_features = 3, out_features = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e4190ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 36, 36])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image       = torch.randn(1, 3, 28, 28)\n",
    "simple_image_layer = torch.nn.Conv2d( in_channels = 3, out_channels = 5 , kernel_size = 3, padding = 5)\n",
    "\n",
    "simple_image_layer(random_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe54909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 9, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 32, kernel_size = 3), \n",
    "    torch.nn.Conv2d(32, 64, kernel_size = 3),\n",
    "    torch.nn.Conv2d(64, 128, kernel_size = 3),\n",
    "    torch.nn.Conv2d(128, 256, kernel_size = 3),\n",
    "    torch.nn.Conv2d(256, 512, kernel_size = 3),\n",
    "    torch.nn.MaxPool2d((2,2))\n",
    ")\n",
    "\n",
    "feature_extractor(random_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c1a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Sequential                               [1, 512, 9, 9]            --\n",
      "├─Conv2d: 1-1                            [1, 32, 26, 26]           896\n",
      "│    └─weight                                                      ├─864\n",
      "│    └─bias                                                        └─32\n",
      "├─Conv2d: 1-2                            [1, 64, 24, 24]           18,496\n",
      "│    └─weight                                                      ├─18,432\n",
      "│    └─bias                                                        └─64\n",
      "├─Conv2d: 1-3                            [1, 128, 22, 22]          73,856\n",
      "│    └─weight                                                      ├─73,728\n",
      "│    └─bias                                                        └─128\n",
      "├─Conv2d: 1-4                            [1, 256, 20, 20]          295,168\n",
      "│    └─weight                                                      ├─294,912\n",
      "│    └─bias                                                        └─256\n",
      "├─Conv2d: 1-5                            [1, 512, 18, 18]          1,180,160\n",
      "│    └─weight                                                      ├─1,179,648\n",
      "│    └─bias                                                        └─512\n",
      "├─MaxPool2d: 1-6                         [1, 512, 9, 9]            --\n",
      "==========================================================================================\n",
      "Total params: 1,568,576\n",
      "Trainable params: 1,568,576\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 547.44\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.11\n",
      "Params size (MB): 6.27\n",
      "Estimated Total Size (MB): 9.39\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [1, 512, 9, 9]            --\n",
       "├─Conv2d: 1-1                            [1, 32, 26, 26]           896\n",
       "│    └─weight                                                      ├─864\n",
       "│    └─bias                                                        └─32\n",
       "├─Conv2d: 1-2                            [1, 64, 24, 24]           18,496\n",
       "│    └─weight                                                      ├─18,432\n",
       "│    └─bias                                                        └─64\n",
       "├─Conv2d: 1-3                            [1, 128, 22, 22]          73,856\n",
       "│    └─weight                                                      ├─73,728\n",
       "│    └─bias                                                        └─128\n",
       "├─Conv2d: 1-4                            [1, 256, 20, 20]          295,168\n",
       "│    └─weight                                                      ├─294,912\n",
       "│    └─bias                                                        └─256\n",
       "├─Conv2d: 1-5                            [1, 512, 18, 18]          1,180,160\n",
       "│    └─weight                                                      ├─1,179,648\n",
       "│    └─bias                                                        └─512\n",
       "├─MaxPool2d: 1-6                         [1, 512, 9, 9]            --\n",
       "==========================================================================================\n",
       "Total params: 1,568,576\n",
       "Trainable params: 1,568,576\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 547.44\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 3.11\n",
       "Params size (MB): 6.27\n",
       "Estimated Total Size (MB): 9.39\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(feature_extractor, input_size=(1, 3, 28, 28), verbose = 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e935a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
